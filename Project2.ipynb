{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The group project is split into 5 tasks. I've already finished the first one, which consists of creating some example pictures of cut out words manually. I've put these examplewords into the folder perpared_words and load them into the variable prepared_words_images so they can be used for the other tasks.\n",
    "\n",
    "All the tasks are built up in such a way, that nobody has to wait on the other people to finish their task. (Except for the last part of task 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 0: Creating and loading testimages\n",
    "Create some test images and load them here so they can be used for task 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "def load_images(data_root, image_paths, target_size):\n",
    "    images = []\n",
    "    for img_path in image_paths:\n",
    "        path = os.path.join(data_root, img_path)\n",
    "        img = Image.open(path)\n",
    "        img = img.convert('RGB')\n",
    "        img = img.resize(target_size)\n",
    "        images.append(np.array(img)) \n",
    "    return images\n",
    "\n",
    "prepared_words_dir = 'prepared_words'\n",
    "prepared_words_paths = os.listdir(prepared_words_dir)\n",
    "\n",
    "target_size = (100, 100)\n",
    "\n",
    "prepared_words_images = load_images(prepared_words_dir, prepared_words_paths, target_size)\n",
    "prepared_words_dataset = []\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(len(prepared_words_images)):\n",
    "    prepared_words_dataset.append((prepared_words_images[i], prepared_words_paths[i][:-4]))\n",
    "    plt.subplot(3, 1, i+1)\n",
    "    plt.imshow(prepared_words_dataset[i][0])\n",
    "    plt.title(prepared_words_dataset[i][1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Dynamic Time Warping\n",
    "Create a method that calculates the distance between two words using Dynamic Time Wrapping. You can use the words in prepared_words_images for testing your method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from dtw import dtw\n",
    "import numpy\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "euclidean = lambda img1, img2 : numpy.sqrt(numpy.sum((img1-img2)**2))\n",
    "\n",
    "def dynamic_time_wrapping(img1, img2):\n",
    "    \n",
    "    img1 = img1 * 255.0/float(img1.max())\n",
    "    img2 = img2 * 255.0/float(img2.max())\n",
    "    dist, cost, acc_cost, path = dtw(img1, img2, dist=euclidean)\n",
    "    return dist, cost, acc_cost, path\n",
    "\n",
    "\n",
    "img1 = prepared_words_images[0]\n",
    "img2 = prepared_words_images[1]\n",
    "\n",
    "dynamic_time_wrapping(img1, img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Train and Apply\n",
    "Write a Class that can be fed multiple pictures. It should then be able to classify a new picture using the dynamicTimeWrapping method above. You can already use the current dynamicTimeWrapping function (which currently just returns random results).\n",
    "You can use the words in prepared_words_images for testing your class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordClassifier:\n",
    "    def __init__(self):\n",
    "        print(\"initialized classifier\")\n",
    "        self.words_arr = []\n",
    "                \n",
    "    def train(self, words):\n",
    "        print('training the model')\n",
    "        # normalize the model and save to the array\n",
    "        for i in range(len(words)):\n",
    "            new_word = cv2.resize(words[i][1], dsize=target_size, interpolation=cv2.INTER_CUBIC)\n",
    "            self.words_arr.append((words[i][0], new_word, words[i][2]))\n",
    "        print('Size of a train array {}'.format(len(self.words_arr)))\n",
    "        \n",
    "    # should return the label of the c\n",
    "    def classify(self, word):\n",
    "        words_scores = {}\n",
    "        # Classify a word\n",
    "        print('classifying a word')\n",
    "        for i in range(len(self.words_arr)):\n",
    "            resized_word = cv2.resize(word, dsize=target_size, interpolation=cv2.INTER_CUBIC)\n",
    "            word_from_arr = self.words_arr[i][1]\n",
    "            min_dist, cost_mtx, acc_cost_matx, warp_path = dynamic_time_wrapping(word_from_arr, resized_word)\n",
    "            words_scores[(self.words_arr[i][0], self.words_arr[i][2])] = min_dist\n",
    "            \n",
    "        sorted_res = sorted(words_scores.items(), key=lambda kv: kv[1])\n",
    "        \n",
    "        # this computes the minimal word in the list\n",
    "        minimal_word_id = min(words_scores, key=words_scores.get) \n",
    "        return minimal_word_id, sorted_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Split up the jpg pages into individual pictures of words\n",
    "Write an algorithm that turns a given page in the images folder into pictures of individual words using the svg file from the ground-truth folder. Currently it just returns the words from prepared_words_images so the people from the other tasks can already use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2 # library needs to be installed first: conda install -c conda-forge opencv\n",
    "\n",
    "# Take a page number as input\n",
    "# Return an array with the corresponding Id as the first argument \n",
    "# and the cropped image(word with white background) as numpy array as the second argument\n",
    "# e.g. [['70-01-01', array([[255, 255, 255, ..., 207, 207, 206],\n",
    "#                           [255, 255, 255, ..., 208, 208, 255],\n",
    "#                           [255, 255, 255, ..., 207, 208, 255],\n",
    "#                           ...,\n",
    "#                           [255, 255, 255, ..., 255, 255, 255],\n",
    "#                           [255, 255, 255, ..., 255, 255, 255],\n",
    "#                           [255, 255, 255, ..., 255, 255, 255]], dtype=uint8)],\n",
    "#       ... ]\n",
    "def loadWordsFromPage(page_number):\n",
    "    path_ground_truth = \"ground-truth/locations/\" + str(page_number) + \".svg\"\n",
    "    path_image = \"images/\" + str(page_number) + \".jpg\"\n",
    "    path_transcription = \"ground-truth/transcription.txt\"\n",
    "    keywords_path = 'task/keywords.txt'\n",
    "    \n",
    "    allCoordinates = []\n",
    "    \n",
    "    with open(path_ground_truth, \"r\") as paths:\n",
    "        for line in paths :\n",
    "            coordinates = []\n",
    "            if \"path\" in line :\n",
    "                startIndexCoordinate = line.find(\"M\") + 1\n",
    "                endIndexCoordinate = line.find(\"Z\")\n",
    "\n",
    "                startIndexId = line.find(\"id=\") + 4\n",
    "                endIndexId = startIndexId + 9\n",
    "\n",
    "                substringCoordinates = line[startIndexCoordinate: endIndexCoordinate]\n",
    "                coordinateStrings = re.findall(\"\\d+\\.\\d+\", substringCoordinates)\n",
    "\n",
    "                substringId = line[startIndexId: endIndexId]\n",
    "\n",
    "                index = 0\n",
    "                for i in range(int(len(coordinateStrings)/2)):\n",
    "                    coordinates.append([float(coordinateStrings[index]), float(coordinateStrings[index+1])])\n",
    "                    index += 2   \n",
    "                allCoordinates.append([substringId, coordinates])  \n",
    "    \n",
    "    transcriptions = {}\n",
    "    keywords = []\n",
    "    \n",
    "    with open(path_transcription, \"r\") as lines:\n",
    "        for line in lines :\n",
    "            transcriptions[line[0:9]] = line[10:len(line)-1]\n",
    "    \n",
    "    with open(path_transcription, \"r\") as lines:\n",
    "        for line in lines :\n",
    "            keywords.append(line[10:len(line)-1])\n",
    "    \n",
    "    \n",
    "    prepared_words_images = []\n",
    "    \n",
    "    img = Image.open(path_image)\n",
    "    img = np.array(img)\n",
    "    \n",
    "    for wordCoordinates in allCoordinates:\n",
    "        if(transcriptions[wordCoordinates[0]] in keywords):\n",
    "            clone = img.copy() \n",
    "\n",
    "            contours = [np.array(wordCoordinates[1], dtype=np.int32)]\n",
    "            mask = np.ones_like(clone)*255\n",
    "            cv2.drawContours(mask,contours,0,0,-1)\n",
    "            out = np.ones_like(clone)*255\n",
    "            out[mask == 0] = clone[mask == 0]\n",
    "\n",
    "            (x, y) = np.where(mask == 0)\n",
    "            (topx, topy) = (np.min(x), np.min(y))\n",
    "            (bottomx, bottomy) = (np.max(x), np.max(y))\n",
    "            out = out[topx:bottomx+1, topy:bottomy+1]\n",
    "            out[out>170] = 255\n",
    "            prepared_words_images.append([wordCoordinates[0], out, transcriptions[wordCoordinates[0]]])\n",
    "\n",
    "    return prepared_words_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_words = loadWordsFromPage(270)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(prepared_words[i][1].shape)\n",
    "    print(type(prepared_words[i][1]))\n",
    "    plt.subplot(5,2,i+1)\n",
    "    plt.imshow(prepared_words[i][1])\n",
    "    print(prepared_words[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_time_wrapping(prepared_words[0][1],prepared_words[0][1])\n",
    "\n",
    "from skimage import data\n",
    "from skimage.color import rgb2gray\n",
    "# print(prepared_words_dataset[1][0])\n",
    "\n",
    "classifier = WordClassifier()\n",
    "classifier.train(prepared_words)\n",
    "\n",
    "# this works\n",
    "results = classifier.classify(prepared_words[5][1])\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4:  Combine all above tasks\n",
    "Use the class and methods above to train and apply our classifier. Maybe write something about accuracy and stuff once the other people have finished their part. Check the exercise hour pdf and https://github.com/lunactic/PatRec17_KWS_Data for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from page 270\n",
      "Loading images from page 271\n",
      "Loading images from page 272\n",
      "Loading images from page 273\n",
      "Loading images from page 274\n",
      "Loading images from page 275\n",
      "Loading images from page 276\n",
      "Loading images from page 277\n",
      "Loading images from page 278\n",
      "Loading images from page 279\n",
      "length is 325\n",
      "---------------------------------------\n",
      "Loading images from page 300\n",
      "Loading images from page 301\n",
      "Loading images from page 302\n",
      "Loading images from page 303\n",
      "Loading images from page 304\n",
      "length is 70\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "train_path = 'task/train.txt'\n",
    "val_path = 'task/valid.txt'\n",
    "keywords_path = 'task/keywords.txt'\n",
    "# Given an input path this returns an array containing arrays of cropped words:\n",
    "# Cropped words:\n",
    "#     An array with the corresponding Id as the first argument \n",
    "#     and the cropped image(word with white background) as numpy array as the second argument\n",
    "def load_data(path):\n",
    "    pages = read_pages_numbers(path)\n",
    "    keywords = read_pages_numbers(keywords_path)\n",
    "    images = []\n",
    "    for i in range(len(pages)):\n",
    "        pagenum = (int)(pages[i])\n",
    "        print('Loading images from page', pagenum)\n",
    "        for word in loadWordsFromPage(pagenum):\n",
    "            if word[2] in keywords:\n",
    "                images.append(word)\n",
    "    print('length is ' + str(len(images)))\n",
    "    print(\"---------------------------------------\")\n",
    "    return images\n",
    "\n",
    "train_images = load_data(train_path)\n",
    "val_images = load_data(val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized classifier\n",
      "training the model\n",
      "Size of a train array 325\n",
      "classifying a word\n",
      "Was O-r-d-e-r-s and got O-r-d-e-r\n",
      "classifying a word\n",
      "Was I-n-s-t-r-u-c-t-i-o-n-s-s_pt and got I-n-s-t-r-u-c-t-i-o-n-s-s_pt\n",
      "classifying a word\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-4b015f0b3c76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-152-4b015f0b3c76>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_a_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# classify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrong\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;31m# Check against ground truth: Is the label taken the same as in the ground truth?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# From the obtained results, calculate statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-152-4b015f0b3c76>\u001b[0m in \u001b[0;36mclassify_images\u001b[0;34m(classifier, images)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mwrong\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Was \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" and got \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-140-105dae68b27d>\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mresized_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_CUBIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mword_from_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mmin_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_cost_matx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarp_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdynamic_time_wrapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_from_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresized_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mwords_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_dist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-139-638748ea1b0d>\u001b[0m in \u001b[0;36mdynamic_time_wrapping\u001b[0;34m(img1, img2)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mimg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mimg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meuclidean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Developer/Pattern Recognition/Project-2/dtw.py\u001b[0m in \u001b[0;36mdtw\u001b[0;34m(x, y, dist, warp, w, s)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mD1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mjrange\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-139-638748ea1b0d>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(img1, img2)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0meuclidean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg2\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdynamic_time_wrapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[1;32m   2074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0;32m-> 2076\u001b[0;31m                           initial=initial)\n\u001b[0m\u001b[1;32m   2077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def read_pages_numbers(directory):\n",
    "    f = open(directory, 'r')\n",
    "    x = f.readlines()\n",
    "    pages = [w.replace('\\n', '') for w in x] # replace trailing sign of new line end of the string\n",
    "    f.close()\n",
    "    return pages\n",
    "    \n",
    "def train_a_classifier(path):\n",
    "    classifier = WordClassifier()\n",
    "    classifier.train(train_images)\n",
    "    return classifier\n",
    "\n",
    "\n",
    "def classify_images(classifier, images):\n",
    "    results = []\n",
    "    correct = 0\n",
    "    wrong = 0\n",
    "    for image in images:\n",
    "        result = classifier.classify(image[1])\n",
    "        results.append(result)\n",
    "        print(\"Was \" + str(image[2]) + \" and got \" + str(result[0][1]))\n",
    "        if (str(image[2]) == str(result[0][1])):\n",
    "            correct = correct + 1\n",
    "        else:\n",
    "            wrong = wrong + 1\n",
    "    return results, correct, wrong\n",
    "\n",
    "\n",
    "def calculate_accuracy(correct, wrong):\n",
    "    accuracy = correct /(correct + wrong) \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def calculate_accuracy(prediction, test_label):\n",
    "    # compare prediction with test labels get array with true and false and count number of trues\n",
    "    correct = np.count_nonzero(prediction == test_label)\n",
    "    return correct / test_label.shape[0]\n",
    "        \n",
    "\n",
    "def main():\n",
    "    # train a  word classifier with images given in the train directory\n",
    "    classifier = train_a_classifier(train_path)\n",
    "    # classify\n",
    "    results, correct, wrong = classify_images(classifier, val_images)\n",
    "    # Check against ground truth: Is the label taken the same as in the ground truth?\n",
    "    # From the obtained results, calculate statistics\n",
    "    accuracy = calculate_accuracy(correct, wrong)\n",
    "    print(accuracy)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
